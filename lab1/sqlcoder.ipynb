{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48d001cd-ab42-4d18-bb88-ce1495184861",
   "metadata": {},
   "source": [
    "# Deploy a Huggingface LLM on SageMaker\n",
    "## Overview\n",
    "Amazon SageMaker provides a fully managed model hosting capability for any machine learning (ML) models for inferences. Specifically, SageMaker hosting offers a broad selection of ML infrastructure and model deployment options to help meet all your ML inference needs. \n",
    "\n",
    "## Deploy SqlCoder LLM on SageMaker\n",
    "SQLCoder is a family of state-of-the-art LLMs for converting natural language questions to SQL queries. [SQLCoder](https://github.com/defog-ai/sqlcoder) has shown impressive benchmark that outperforms GPT4 and GPT4-Turbo on text to SQL generation task. In this lab, we'll deploy a quantized version of this model to a SageMaker endpoint using SageMaker LMI, running inference on it and validate the inference results. To optimize the deployment and inference, we'll use SageMaker LMI to host the model in a SageMaker endpoint.\n",
    "\n",
    "## SageMaker LMI Containers\n",
    "SageMaker LMI containers are a set of high performance Docker Containers purpose built for large language model (LLM) inference. With these containers you can leverage high performance open-source inference libraries like vLLM, TensorRT-LLM, DeepSpeed, Transformers NeuronX to deploy LLMs on AWS SageMaker Endpoints. These containers bundle together a model server with open-source inference libraries to deliver an all-in-one LLM serving solution. We provide quick start notebooks that get you deploying popular open source models in minutes, and advanced guides to maximize performance of your endpoint.\n",
    "\n",
    "The lab can be organized into the following key steps:\n",
    "1. Create a model service configuration file that specifies a 4-Bit quantized SQLCoder available on Huggingface Hub.\n",
    "2. Deploy the model to SageMaker as a realtime endpoint using SageMaker LMI.\n",
    "3. Test and verify the model is deployed successfully and able to send inference requests to the model for SQL query generation.\n",
    "4. Setup a test database called **Chinook** running as SQLite, an in memory database.\n",
    "5. Sends requests to the SQLCoder LLM using natural language as the LLM prompt.\n",
    "6. Invokes the model and receives a response query.\n",
    "7. Use the response query to invoke against the test SQLite database and verify the results.\n",
    "\n",
    "\n",
    "\n",
    "> This notebook has been tested in a **`SageMaker Distribution 1.4`** Image using **Base Python 3.0 kernel** on  **ml.m5.large** instance.\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3975bfbd-9b06-4207-9244-6478c2ddeb40",
   "metadata": {},
   "source": [
    "First, let's install all the required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76b7f5d5-bc86-4bf6-9429-b7c220f6ad8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aiobotocore 2.7.0 requires botocore<1.31.65,>=1.31.16, but you have botocore 1.34.76 which is incompatible.\n",
      "autogluon-multimodal 0.8.2 requires transformers[sentencepiece]<4.32.0,>=4.31.0, but you have transformers 4.39.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install boto3 sagemaker fmeval jsonlines transformers -Uq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a4dbc39-b906-40b4-b626-59c32a30e12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas==2.1.4\n",
      "  Using cached pandas-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting numpy<2,>=1.22.4 (from pandas==2.1.4)\n",
      "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas==2.1.4)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas==2.1.4)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.1 (from pandas==2.1.4)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas==2.1.4)\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Using cached pandas-2.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pytz, tzdata, six, numpy, python-dateutil, pandas\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "autogluon-multimodal 0.8.2 requires transformers[sentencepiece]<4.32.0,>=4.31.0, but you have transformers 4.39.3 which is incompatible.\n",
      "autovizwidget 0.21.0 requires pandas<2.0.0,>=0.20.1, but you have pandas 2.1.4 which is incompatible.\n",
      "hdijupyterutils 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.1.4 which is incompatible.\n",
      "jupyter-scheduler 2.4.0 requires pytz==2023.3, but you have pytz 2024.1 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.1.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.3 pandas-2.1.4 python-dateutil-2.8.2 pytz-2023.3 six-1.16.0 tzdata-2023.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Iv pandas==2.1.4 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91a64ed4-7886-4e12-8433-8e3b4440beca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92ac487-6a30-4c83-9248-b9b4080767e3",
   "metadata": {},
   "source": [
    "Import the library to be used throughout the lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feaaa4d6-b004-4d71-a802-fad9928d86a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import Model, image_uris, serializers, deserializers\n",
    "import json\n",
    "import sqlite3\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "region = sess._region_name  # region name of the current SageMaker Studio environment\n",
    "account_id = sess.account_id()  # account_id of the current SageMaker Studio environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a525423-1a67-41a2-9a29-913b44b0ee05",
   "metadata": {},
   "source": [
    "# Deploy a Huggingface LLM Using SageMaker LMI\n",
    "In order to deploy an LLM using SageMaker LMI, we need to setup a configuration file with key information about how the model should be hosted and serving inferences. For instance, to deploy a huggingface LLM, we only need to provide the huggingface model ID in the configuration, SageMaker LMI will automatically take care of downloading the model and loads the model in the serving container. SgaeMaker LMI is highly configurable to provide users the flexibility in choosing the most optmized configuration to serve their models. Please refer to this [link](https://docs.aws.amazon.com/sagemaker/latest/dg/large-model-inference-configuration.html) to lear more about the the avaialble configuration parameters for LMI. \n",
    "\n",
    "The following diagram gives an overview of a SageMaker LMI deployment pipeline you can use to deploy your models.\n",
    "\n",
    "![SageMaker LMI Deployment](images/sm_lmi_pipeline.jpg)\n",
    "\n",
    "This [blog post](https://aws.amazon.com/blogs/machine-learning/boost-inference-performance-for-llms-with-new-amazon-sagemaker-containers/) provides great amount of detail about SageMaker LMI, the inference optimization frameworks that it supports and the performance benchmarks for each of the supported frameworks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b78b612-749e-4eab-93bb-17b31ce833d0",
   "metadata": {},
   "source": [
    "First, we provide a serving.properties file with the model specific details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c25bd807-45bb-4482-8c67-4acade890b61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing serving.properties\n"
     ]
    }
   ],
   "source": [
    "%%writefile serving.properties\n",
    "engine=Python\n",
    "option.model_id=TheBloke/sqlcoder-34b-alpha-GPTQ\n",
    "option.task=text-generation\n",
    "option.trust_remote_code=true\n",
    "option.tensor_parallel_degree=max\n",
    "option.rolling_batch=auto\n",
    "option.quantize=gptq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65d2917-9a34-46e2-bd9f-8442dd5dbf43",
   "metadata": {},
   "source": [
    "In the following, we'll create a tar file with only the service.properties file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c12d6f8-ebc4-4ebb-84d2-bdefe07c4d9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model/\n",
      "model/serving.properties\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "mkdir model\n",
    "mv serving.properties model/\n",
    "tar czvf sqlcoder.tar.gz model/\n",
    "rm -rf model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b57672-ed9a-44dc-a8ff-705955d71c7d",
   "metadata": {},
   "source": [
    "Define an LMI container to use by specifying the framework and the framework version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d380ac71-0425-4583-a5ec-ce01ff2bc262",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_uri = image_uris.retrieve(\n",
    "        framework=\"djl-deepspeed\",\n",
    "        region=sess.boto_session.region_name,\n",
    "        version=\"0.26.0\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab697e40-a053-4999-b75c-d7c72fa5e0a7",
   "metadata": {},
   "source": [
    "Uploads the .gz file to S3 for serving container to pick up at model deployment time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b99630f-d660-42aa-912f-27ee97946160",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 Code or Model tar ball uploaded to --- &gt; s3://sagemaker-us-east-1-602900100639/models/large-model-lmi/sqlcoder/sqlcoder.tar.gz\n"
     ]
    }
   ],
   "source": [
    "s3_code_prefix = \"models/large-model-lmi/sqlcoder\"\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "code_artifact = sess.upload_data(\"sqlcoder.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar ball uploaded to --- &gt; {code_artifact}\")\n",
    "\n",
    "model = Model(image_uri=image_uri, model_data=code_artifact, role=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcced03-fac4-4cb8-a3ac-735d4021eb9c",
   "metadata": {},
   "source": [
    "Specifies the mode and use SageMaker SDK to trigger the model deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "192747f1-944b-4970-9155-f9a528e6c91e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "instance_type = \"ml.g5.2xlarge\"\n",
    "endpoint_name = sagemaker.utils.name_from_base(\"sqlcoder-lmi-model\")\n",
    "\n",
    "model.deploy(initial_instance_count=1,\n",
    "             instance_type=instance_type,\n",
    "             endpoint_name=endpoint_name,\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8b1efc-98a5-4896-8126-951d3e2e039d",
   "metadata": {},
   "source": [
    "Once the model is deployed successfully, we can start running inference against the endpoint. SageMaker SDK provides a Predictor class that helps simplifying inference request and response. In the following cell, we'll create a predictor object for the endpoint so that we could use it for generating SQL query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f98b34f-ecb1-4cdc-b132-790db5454570",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# our requests and responses will be in json format so we specify the serializer and the deserializer\n",
    "predictor = sagemaker.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sess,\n",
    "    serializer=serializers.JSONSerializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d975f9-28f6-4431-b3cc-d9ea8202285b",
   "metadata": {},
   "source": [
    "Here's a sample prompt template that consists of an instruction with placeholders to be sent to SQLCoder LLM for inference. You can modify the template and observe how different prompts would impact the response from the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "786a0921-86d1-4751-b564-944ba8451c90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"### Task\n",
    "Generate a SQL query to answer [QUESTION]{user_question}[/QUESTION]\n",
    "\n",
    "### Instructions\n",
    "- If you cannot answer the question with the available database schema, return 'I do not know'\n",
    "\n",
    "### Database Schema\n",
    "The query will run on a database with the following schema:\n",
    "{table_metadata_string}\n",
    "\n",
    "### Answer\n",
    "Given the database schema, here is the SQL query that answers [QUESTION]{user_question}[/QUESTION]\n",
    "[SQL]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13445662-bb02-461a-86d2-0e837785510f",
   "metadata": {},
   "source": [
    "## SQL Query Validation\n",
    "At this point, we will start validating the LLM capability by sending the generated SQL query to a test database. For this example, We use [Chinook](https://github.com/lerocha/chinook-database) database which contains sample Music album sales across music companies. We also created `metadata.sql` that contains the DDL for the database schema. The schema information is to be fed to the prompt template above to complete a prompt. \n",
    "\n",
    "The following database diagram illustrates the chinook database tables and their relationships.\n",
    "\n",
    "![chinook schema](images/chinook-schema.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57338c51-b096-43bb-a90c-2ac36773bb3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata_file = \"metadata.sql\"\n",
    "with open(metadata_file, \"r\") as f:\n",
    "    table_metadata_string = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed468f8e-6b09-4e91-95b8-f52ab35afcc1",
   "metadata": {},
   "source": [
    "Let's ask a question using natural language relevant to the given DB schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec0e094c-dc9f-4379-9b09-7112a1b3598c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question = \"how many unique albums are there?\"\n",
    "prompt = prompt_template.format(user_question=question, table_metadata_string=table_metadata_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f497162c-3439-4c1c-acc6-a58d46017577",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Task\n",
      "Generate a SQL query to answer [QUESTION]how many unique albums are there?[/QUESTION]\n",
      "\n",
      "### Instructions\n",
      "- If you cannot answer the question with the available database schema, return 'I do not know'\n",
      "\n",
      "### Database Schema\n",
      "The query will run on a database with the following schema:\n",
      "CREATE TABLE [Album]\n",
      "(\n",
      "    [AlbumId] INTEGER  NOT NULL,\n",
      "    [Title] NVARCHAR(160)  NOT NULL,\n",
      "    [ArtistId] INTEGER  NOT NULL,\n",
      "    CONSTRAINT [PK_Album] PRIMARY KEY  ([AlbumId]),\n",
      "    FOREIGN KEY ([ArtistId]) REFERENCES [Artist] ([ArtistId])\n",
      "                ON DELETE NO ACTION ON UPDATE NO ACTION\n",
      ");\n",
      "\n",
      "CREATE TABLE [Artist]\n",
      "(\n",
      "    [ArtistId] INTEGER  NOT NULL,\n",
      "    [Name] NVARCHAR(120),\n",
      "    CONSTRAINT [PK_Artist] PRIMARY KEY  ([ArtistId])\n",
      ");\n",
      "\n",
      "CREATE TABLE [Customer]\n",
      "(\n",
      "    [CustomerId] INTEGER  NOT NULL,\n",
      "    [FirstName] NVARCHAR(40)  NOT NULL,\n",
      "    [LastName] NVARCHAR(20)  NOT NULL,\n",
      "    [Company] NVARCHAR(80),\n",
      "    [Address] NVARCHAR(70),\n",
      "    [City] NVARCHAR(40),\n",
      "    [State] NVARCHAR(40),\n",
      "    [Country] NVARCHAR(40),\n",
      "    [PostalCode] NVARCHAR(10),\n",
      "    [Phone] NVARCHAR(24),\n",
      "    [Fax] NVARCHAR(24),\n",
      "    [Email] NVARCHAR(60)  NOT NULL,\n",
      "    [SupportRepId] INTEGER,\n",
      "    CONSTRAINT [PK_Customer] PRIMARY KEY  ([CustomerId]),\n",
      "    FOREIGN KEY ([SupportRepId]) REFERENCES [Employee] ([EmployeeId])\n",
      "                ON DELETE NO ACTION ON UPDATE NO ACTION\n",
      ");\n",
      "\n",
      "CREATE TABLE [Employee]\n",
      "(\n",
      "    [EmployeeId] INTEGER  NOT NULL,\n",
      "    [LastName] NVARCHAR(20)  NOT NULL,\n",
      "    [FirstName] NVARCHAR(20)  NOT NULL,\n",
      "    [Title] NVARCHAR(30),\n",
      "    [ReportsTo] INTEGER,\n",
      "    [BirthDate] DATETIME,\n",
      "    [HireDate] DATETIME,\n",
      "    [Address] NVARCHAR(70),\n",
      "    [City] NVARCHAR(40),\n",
      "    [State] NVARCHAR(40),\n",
      "    [Country] NVARCHAR(40),\n",
      "    [PostalCode] NVARCHAR(10),\n",
      "    [Phone] NVARCHAR(24),\n",
      "    [Fax] NVARCHAR(24),\n",
      "    [Email] NVARCHAR(60),\n",
      "    CONSTRAINT [PK_Employee] PRIMARY KEY  ([EmployeeId]),\n",
      "    FOREIGN KEY ([ReportsTo]) REFERENCES [Employee] ([EmployeeId])\n",
      "                ON DELETE NO ACTION ON UPDATE NO ACTION\n",
      ");\n",
      "\n",
      "CREATE TABLE [Genre]\n",
      "(\n",
      "    [GenreId] INTEGER  NOT NULL,\n",
      "    [Name] NVARCHAR(120),\n",
      "    CONSTRAINT [PK_Genre] PRIMARY KEY  ([GenreId])\n",
      ");\n",
      "\n",
      "CREATE TABLE [Invoice]\n",
      "(\n",
      "    [InvoiceId] INTEGER  NOT NULL,\n",
      "    [CustomerId] INTEGER  NOT NULL,\n",
      "    [InvoiceDate] DATETIME  NOT NULL,\n",
      "    [BillingAddress] NVARCHAR(70),\n",
      "    [BillingCity] NVARCHAR(40),\n",
      "    [BillingState] NVARCHAR(40),\n",
      "    [BillingCountry] NVARCHAR(40),\n",
      "    [BillingPostalCode] NVARCHAR(10),\n",
      "    [Total] NUMERIC(10,2)  NOT NULL,\n",
      "    CONSTRAINT [PK_Invoice] PRIMARY KEY  ([InvoiceId]),\n",
      "    FOREIGN KEY ([CustomerId]) REFERENCES [Customer] ([CustomerId])\n",
      "                ON DELETE NO ACTION ON UPDATE NO ACTION\n",
      ");\n",
      "\n",
      "CREATE TABLE [InvoiceLine]\n",
      "(\n",
      "    [InvoiceLineId] INTEGER  NOT NULL,\n",
      "    [InvoiceId] INTEGER  NOT NULL,\n",
      "    [TrackId] INTEGER  NOT NULL,\n",
      "    [UnitPrice] NUMERIC(10,2)  NOT NULL,\n",
      "    [Quantity] INTEGER  NOT NULL,\n",
      "    CONSTRAINT [PK_InvoiceLine] PRIMARY KEY  ([InvoiceLineId]),\n",
      "    FOREIGN KEY ([InvoiceId]) REFERENCES [Invoice] ([InvoiceId])\n",
      "                ON DELETE NO ACTION ON UPDATE NO ACTION,\n",
      "    FOREIGN KEY ([TrackId]) REFERENCES [Track] ([TrackId])\n",
      "                ON DELETE NO ACTION ON UPDATE NO ACTION\n",
      ");\n",
      "\n",
      "CREATE TABLE [MediaType]\n",
      "(\n",
      "    [MediaTypeId] INTEGER  NOT NULL,\n",
      "    [Name] NVARCHAR(120),\n",
      "    CONSTRAINT [PK_MediaType] PRIMARY KEY  ([MediaTypeId])\n",
      ");\n",
      "\n",
      "CREATE TABLE [Playlist]\n",
      "(\n",
      "    [PlaylistId] INTEGER  NOT NULL,\n",
      "    [Name] NVARCHAR(120),\n",
      "    CONSTRAINT [PK_Playlist] PRIMARY KEY  ([PlaylistId])\n",
      ");\n",
      "\n",
      "CREATE TABLE [PlaylistTrack]\n",
      "(\n",
      "    [PlaylistId] INTEGER  NOT NULL,\n",
      "    [TrackId] INTEGER  NOT NULL,\n",
      "    CONSTRAINT [PK_PlaylistTrack] PRIMARY KEY  ([PlaylistId], [TrackId]),\n",
      "    FOREIGN KEY ([PlaylistId]) REFERENCES [Playlist] ([PlaylistId])\n",
      "                ON DELETE NO ACTION ON UPDATE NO ACTION,\n",
      "    FOREIGN KEY ([TrackId]) REFERENCES [Track] ([TrackId])\n",
      "                ON DELETE NO ACTION ON UPDATE NO ACTION\n",
      "\n",
      "CREATE TABLE [Track]\n",
      "(\n",
      "    [TrackId] INTEGER  NOT NULL,\n",
      "    [Name] NVARCHAR(200)  NOT NULL,\n",
      "    [AlbumId] INTEGER,\n",
      "    [MediaTypeId] INTEGER  NOT NULL,\n",
      "    [GenreId] INTEGER,\n",
      "    [Composer] NVARCHAR(220),\n",
      "    [Milliseconds] INTEGER  NOT NULL,\n",
      "    [Bytes] INTEGER,\n",
      "    [UnitPrice] NUMERIC(10,2)  NOT NULL,\n",
      "    CONSTRAINT [PK_Track] PRIMARY KEY  ([TrackId]),\n",
      "    FOREIGN KEY ([AlbumId]) REFERENCES [Album] ([AlbumId])\n",
      "                ON DELETE NO ACTION ON UPDATE NO ACTION,\n",
      "    FOREIGN KEY ([GenreId]) REFERENCES [Genre] ([GenreId])\n",
      "                ON DELETE NO ACTION ON UPDATE NO ACTION,\n",
      "    FOREIGN KEY ([MediaTypeId]) REFERENCES [MediaType] ([MediaTypeId])\n",
      "                ON DELETE NO ACTION ON UPDATE NO ACTION\n",
      ");\n",
      "\n",
      "### Answer\n",
      "Given the database schema, here is the SQL query that answers [QUESTION]how many unique albums are there?[/QUESTION]\n",
      "[SQL]\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af59bd41-5d41-4fc8-aa8d-da0fcbe783db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def invoke_model(prompt):\n",
    "    response = predictor.predict(\n",
    "        {\"inputs\": prompt, \"parameters\": {\"max_tokens\":1024}}\n",
    "    )\n",
    "    output = response.decode(\"utf-8\")\n",
    "    full_output_text = json.loads(output)[\"generated_text\"]\n",
    "    sql_query = full_output_text.split(\"[/SQL]\")[0]\n",
    "    return sql_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e885c206-d22e-42db-a4bb-3dea50f5c106",
   "metadata": {},
   "source": [
    "Invokes the LLM for SQL generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "695cce3f-7e0a-4245-b493-f25a39306577",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql_query = invoke_model(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e59a84a-4e62-4aa5-a758-eef2242fed00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT COUNT(DISTINCT Album.AlbumId) AS total_albums FROM Album;\n"
     ]
    }
   ],
   "source": [
    "print(sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ef24e7-4660-42df-b9c8-7cc613304992",
   "metadata": {},
   "source": [
    "Next, we'll start creating a database connection to a test db hosted in memory. \n",
    "We'll also download the dataset from the given link so that they could be populated into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6208d128-75ba-47e0-8df1-e5169a12c139",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "connection = sqlite3.connect(\"test.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3706aba-08b7-477a-af7c-24789d726a20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_file_url = \"https://github.com/lerocha/chinook-database/releases/download/v1.4.5/Chinook_Sqlite.sqlite\"\n",
    "db_filename = \"Chinook_Sqlite.sqlite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a78c8d89-83d3-4039-aa9c-164c17950006",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5723b0e6-9808-4f4a-951d-7dd3ff85532e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Chinook_Sqlite.sqlite', <http.client.HTTPMessage at 0x7f66eca80d90>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urlretrieve(db_file_url, db_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6cf31d6-cf24-465d-b97b-7ba58b74314f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_query(query):\n",
    "    # Create a SQL connection to our SQLite database\n",
    "    con = sqlite3.connect(db_filename)\n",
    "    cur = con.cursor()\n",
    "\n",
    "    # The result of a \"cursor.execute\" can be iterated over by row\n",
    "    for row in cur.execute(query):\n",
    "        print(row)\n",
    "    # Be sure to close the connection\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317d496f-8415-47f1-8d35-3fee9e49f689",
   "metadata": {},
   "source": [
    "## Use SageMaker Foundation Model Evaluation (fmeval) to evaluate SQLCoder\n",
    "### Foundation Model Evaluations Library\n",
    "fmeval is an open source library to evaluate Large Language Models (LLMs) in order to help select the best LLM for your use case. The library evaluates LLMs for the following tasks:\n",
    "\n",
    "* Open-ended generation - The production of natural human responses to text that does not have a pre-defined structure.\n",
    "* Text summarization - The generation of a condensed summary retaining the key information contained in a longer text.\n",
    "* Question Answering - The generation of a relevant and accurate response to an answer.\n",
    "* Classification - Assigning a category, such as a label or score to text, based on its content.\n",
    "\n",
    "To learn more about how to use `fmeval` library, please follow this [github](https://github.com/aws/fmeval) repository and [documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-foundation-model-evaluate-overview.html).\n",
    "\n",
    "For SQL generation task, we'll leverage the Q&A evaluation task to measure the accuracy of the generated query.\n",
    "For this lab, we've curated a few Q&A smaples to serve as the ground truth data. The `fmeval` will use these data to perform evaluation on the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26296f72-b84e-4a3d-ba05-4dccc26630b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many artists whose name starts with 'Adam'?\n",
      "Model output: SELECT COUNT(ArtistId) AS ArtistCount FROM Artist WHERE Name like 'Adam%';\n",
      "==============================\n",
      "Question: how many unique albums are there?\n",
      "Model output: SELECT COUNT(DISTINCT Album.AlbumId) AS total_albums FROM Album;\n",
      "==============================\n",
      "Question: How many customers do employee with first name of 'Jane' has?\n",
      "Model output: SELECT COUNT(DISTINCT c.customerid) AS total_customers FROM customer c JOIN employee e ON c.supportrepid = e\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "\n",
    "input_file = \"fmeval_data_inputs.jsonl\"\n",
    "output_file = \"fmeval_data_outputs.jsonl\"\n",
    "\n",
    "# For each line in `input_file`, invoke the model using the input from that line,\n",
    "# augment the line with the invocation results, and write the augmented line to `output_file`.\n",
    "with jsonlines.open(input_file) as input_fh, jsonlines.open(output_file, \"w\") as output_fh:\n",
    "    for line in input_fh:\n",
    "        if \"question\" in line:\n",
    "            question = line[\"question\"]\n",
    "            print(f\"Question: {question}\")\n",
    "            p = prompt_template.format(user_question=question, table_metadata_string=table_metadata_string)\n",
    "            output = invoke_model(p)\n",
    "            print(f\"Model output: {output}\")\n",
    "            print(\"==============================\")\n",
    "            line[\"model_output\"] = output\n",
    "            output_fh.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0450ba7-dc9a-473f-8a65-5751f4b19457",
   "metadata": {},
   "source": [
    "## FMEval Setup\n",
    "\n",
    "In this section, we will perform the evaluation on the model that we deployed. We will a ModelRunner to evaluate the model on Accuracy using the FMEval library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e71c38a2-ac07-426f-a888-9acaf88d3a62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fmeval.data_loaders.data_config import DataConfig\n",
    "from fmeval.constants import MIME_TYPE_JSONLINES\n",
    "from fmeval.eval_algorithms.qa_accuracy import QAAccuracy, QAAccuracyConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b55711-2398-44a7-829c-8630ef31e412",
   "metadata": {},
   "source": [
    "### Data Config Setup\n",
    "Below, we create a DataConfig for the local dataset file we just created, trex_sample_with_model_outputs.jsonl.\n",
    "\n",
    "* dataset_name is just an identifier for your own reference\n",
    "* dataset_uri is either a local path to a file or an S3 URI\n",
    "* dataset_mime_type is the MIME type of the dataset. Currently, JSON and JSON Lines are supported.\n",
    "* model_input_location, target_output_location, and model_output_location are JMESPath queries used to find the model inputs, target outputs, and model outputs within the dataset. The values that you specify here depend on the structure of the dataset itself. Take a look at trex_sample_with_model_outputs.jsonl to see where \"question\", \"answers\", and \"model_output\" show up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "377f0764-7e5f-4d97-82ff-32c508c17df1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = DataConfig(\n",
    "    dataset_name=\"llm_sample_with_model_outputs\",\n",
    "    dataset_uri=\"fmeval_data_outputs.jsonl\",\n",
    "    dataset_mime_type=MIME_TYPE_JSONLINES,\n",
    "    model_input_location=\"question\",\n",
    "    target_output_location=\"answers\",\n",
    "    model_output_location=\"model_output\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025dee41-809b-426c-a12e-a1a20a9b235c",
   "metadata": {},
   "source": [
    "## Run Evaluation\n",
    "In use cases that we demonstrate in the other example notebooks, we usually pass a model runner and prompt template to the evaluate method of our evaluation algorithm. However, since our dataset already contains all of the model inference outputs, we only need to pass our dataset config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af8a0938-94e6-4fe2-bffd-b3d049fd620a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 06:43:35,652\tWARNING services.py:1996 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 414179328 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=0.97gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2024-04-03 06:43:36,838\tINFO worker.py:1724 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Read progress 0:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Read progress 0:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 06:43:43,005\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Repartition]\n",
      "2024-04-03 06:43:43,007\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-04-03 06:43:43,009\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Repartition 1:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Split Repartition 2:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 06:43:43,207\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> ActorPoolMapOperator[Map(QAAccuracyScores)]\n",
      "2024-04-03 06:43:43,209\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-04-03 06:43:43,213\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n",
      "2024-04-03 06:43:43,255\tINFO actor_pool_map_operator.py:114 -- Map(QAAccuracyScores): Waiting for 1 pool actors to start...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_MapWorker pid=530)\u001b[0m sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "\u001b[36m(_MapWorker pid=530)\u001b[0m sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m /opt/conda/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m   if isinstance(items[0], TensorArrayElement):\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m /opt/conda/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m   return items[0]\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m /opt/conda/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m   if isinstance(items[0], TensorArrayElement):\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m /opt/conda/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m   return items[0]\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m /opt/conda/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m   if isinstance(items[0], TensorArrayElement):\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m /opt/conda/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m   return items[0]\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m /opt/conda/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m   if isinstance(items[0], TensorArrayElement):\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m /opt/conda/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m   return items[0]\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m /opt/conda/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m   if isinstance(items[0], TensorArrayElement):\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m /opt/conda/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m   return items[0]\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m /opt/conda/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m   if isinstance(items[0], TensorArrayElement):\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m /opt/conda/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m   return items[0]\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m /opt/conda/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m   if isinstance(items[0], TensorArrayElement):\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m /opt/conda/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m   return items[0]\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m /opt/conda/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m   if isinstance(items[0], TensorArrayElement):\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m /opt/conda/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m   return items[0]\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m /opt/conda/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:67: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m   if isinstance(items[0], TensorArrayElement):\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m /opt/conda/lib/python3.10/site-packages/ray/data/_internal/pandas_block.py:89: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\u001b[36m(MapWorker(Map(QAAccuracyScores)) pid=530)\u001b[0m   return items[0]\n",
      "2024-04-03 06:43:47,552\tINFO dataset.py:2488 -- Tip: Use `take_batch()` instead of `take() / show()` to return records in pandas or numpy batch format.\n",
      "2024-04-03 06:43:47,562\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-04-03 06:43:47,564\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-04-03 06:43:47,566\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Aggregate 1:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 2:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 3:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 06:43:48,462\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-04-03 06:43:48,466\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-04-03 06:43:48,469\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Aggregate 1:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 2:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 3:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 06:43:49,630\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-04-03 06:43:49,631\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-04-03 06:43:49,633\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Aggregate 1:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 2:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 3:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 06:43:49,806\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-04-03 06:43:49,808\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-04-03 06:43:49,808\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Aggregate 1:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 2:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 3:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 06:43:49,982\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> AllToAllOperator[Aggregate] -> LimitOperator[limit=1]\n",
      "2024-04-03 06:43:49,984\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-04-03 06:43:49,986\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "- Aggregate 1:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Map 2:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffle Reduce 3:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 06:43:50,142\tWARNING plan.py:588 -- Warning: The Ray cluster currently does not have any available CPUs. The Dataset job will hang unless more CPUs are freed up. A common reason is that cluster resources are used by Actors or Tune trials; see the following link for more details: https://docs.ray.io/en/latest/data/data-internals.html#ray-data-and-tune\n",
      "2024-04-03 06:43:50,150\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[Map(<lambda>)]\n",
      "2024-04-03 06:43:50,153\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-04-03 06:43:50,154\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-03 06:43:51,663\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[Map(<lambda>)]\n",
      "2024-04-03 06:43:51,663\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=True, actor_locality_enabled=True, verbose_progress=False)\n",
      "2024-04-03 06:43:51,665\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running 0:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_algo = QAAccuracy(QAAccuracyConfig(target_output_delimiter=\"<OR>\"))\n",
    "eval_output = eval_algo.evaluate(dataset_config=config, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0750d7f4-c8fe-48d0-ac64-5d8418c5f9b5",
   "metadata": {},
   "source": [
    "### Parse Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77f6b4f4-467e-427c-8a73-eafb535b3f47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"eval_name\": \"qa_accuracy\",\n",
      "        \"dataset_name\": \"llm_sample_with_model_outputs\",\n",
      "        \"dataset_scores\": [\n",
      "            {\n",
      "                \"name\": \"f1_score\",\n",
      "                \"value\": 0.9555555555555556\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"exact_match_score\",\n",
      "                \"value\": 0.6666666666666666\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"quasi_exact_match_score\",\n",
      "                \"value\": 0.6666666666666666\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"precision_over_words\",\n",
      "                \"value\": 1.0\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"recall_over_words\",\n",
      "                \"value\": 0.9215686274509803\n",
      "            }\n",
      "        ],\n",
      "        \"prompt_template\": null,\n",
      "        \"category_scores\": null,\n",
      "        \"output_path\": \"/tmp/eval_results/qa_accuracy_llm_sample_with_model_outputs.jsonl\",\n",
      "        \"error\": null\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Pretty-print the evaluation output (notice the score).\n",
    "import json\n",
    "print(json.dumps(eval_output, default=vars, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f67a295e-972d-4e76-9a4b-c664cbc26122",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[EvalScore(name='f1_score', value=0.9555555555555556),\n",
       " EvalScore(name='exact_match_score', value=0.6666666666666666),\n",
       " EvalScore(name='quasi_exact_match_score', value=0.6666666666666666),\n",
       " EvalScore(name='precision_over_words', value=1.0),\n",
       " EvalScore(name='recall_over_words', value=0.9215686274509803)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_output[0].dataset_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3385073e-0a61-497e-84bb-ac1854241cbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a Pandas DataFrame to visualize the results\n",
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "\n",
    "# We obtain the path to the results file from \"output_path\" in the cell above\n",
    "with open(\"fmeval_data_outputs.jsonl\", \"r\") as file:\n",
    "    for line in file:\n",
    "        data_dict = json.loads(line)\n",
    "        data_dict[\"eval_f1_score\"] = eval_output[0].dataset_scores[0].value\n",
    "        data_dict[\"eval_exact_match_score\"] = eval_output[0].dataset_scores[1].value\n",
    "        data_dict[\"eval_quasi_exact_match_score\"] = eval_output[0].dataset_scores[2].value\n",
    "        data_dict[\"eval_quasi_precision_over_words_score\"] = eval_output[0].dataset_scores[3].value\n",
    "        data_dict[\"eval_quasi_recall_over_words_score\"] = eval_output[0].dataset_scores[4].value\n",
    "        data.append(data_dict)\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cef015fa-6100-4edd-bd50-a3d3e426bad8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answers</th>\n",
       "      <th>knowledge_category</th>\n",
       "      <th>question</th>\n",
       "      <th>model_output</th>\n",
       "      <th>eval_f1_score</th>\n",
       "      <th>eval_exact_match_score</th>\n",
       "      <th>eval_quasi_exact_match_score</th>\n",
       "      <th>eval_quasi_precision_over_words_score</th>\n",
       "      <th>eval_quasi_recall_over_words_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SELECT COUNT(ArtistId) AS ArtistCount FROM Art...</td>\n",
       "      <td>SQL</td>\n",
       "      <td>How many artists whose name starts with 'Adam'?</td>\n",
       "      <td>SELECT COUNT(ArtistId) AS ArtistCount FROM Art...</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.921569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SELECT COUNT(DISTINCT Album.AlbumId) AS total_...</td>\n",
       "      <td>SQL</td>\n",
       "      <td>how many unique albums are there?</td>\n",
       "      <td>SELECT COUNT(DISTINCT Album.AlbumId) AS total_...</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.921569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SELECT e.FirstName, COUNT(DISTINCT c.customeri...</td>\n",
       "      <td>SQL</td>\n",
       "      <td>How many customers do employee with first name...</td>\n",
       "      <td>SELECT COUNT(DISTINCT c.customerid) AS total_c...</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.921569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             answers knowledge_category  \\\n",
       "0  SELECT COUNT(ArtistId) AS ArtistCount FROM Art...                SQL   \n",
       "1  SELECT COUNT(DISTINCT Album.AlbumId) AS total_...                SQL   \n",
       "2  SELECT e.FirstName, COUNT(DISTINCT c.customeri...                SQL   \n",
       "\n",
       "                                            question  \\\n",
       "0    How many artists whose name starts with 'Adam'?   \n",
       "1                  how many unique albums are there?   \n",
       "2  How many customers do employee with first name...   \n",
       "\n",
       "                                        model_output  eval_f1_score  \\\n",
       "0  SELECT COUNT(ArtistId) AS ArtistCount FROM Art...       0.955556   \n",
       "1  SELECT COUNT(DISTINCT Album.AlbumId) AS total_...       0.955556   \n",
       "2  SELECT COUNT(DISTINCT c.customerid) AS total_c...       0.955556   \n",
       "\n",
       "   eval_exact_match_score  eval_quasi_exact_match_score  \\\n",
       "0                0.666667                      0.666667   \n",
       "1                0.666667                      0.666667   \n",
       "2                0.666667                      0.666667   \n",
       "\n",
       "   eval_quasi_precision_over_words_score  eval_quasi_recall_over_words_score  \n",
       "0                                    1.0                            0.921569  \n",
       "1                                    1.0                            0.921569  \n",
       "2                                    1.0                            0.921569  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7168e3-7c90-4792-a550-206703e22188",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "In this lab, we learn how to deploy a Huggingface model (SQLCoder) in a SageMaker Deep Learning Container using SageMaker SDK. \n",
    "\n",
    "To test the deployed LLM, we used a natural language to ask a question and have the LLM to generate a relevant SQL query based on the given context. \n",
    "\n",
    "We also loaded a test database using SQLLite with sample data so that we could use the generated query against the database to fetch the results. \n",
    "\n",
    "Additionally, we used an open source FM evaluation framework called FMEval to evaluate the performance of the model. \n",
    "\n",
    "Finally, we showed the evaluation results as a pandas dataframe for visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ed5d4a-fffb-4e0f-9a76-72496b603cfe",
   "metadata": {},
   "source": [
    "# Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278f088f-a9d3-4274-ae1c-29850876353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.delete_endpoint(endpoint_name)\n",
    "sess.delete_endpoint_config(endpoint_name)\n",
    "model.delete_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
