{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e45bc13-4471-4070-885e-cefc9fa59351",
   "metadata": {},
   "source": [
    "# Full Managed model deployment using SageMaker Deployment Guardrail\n",
    "## Introduction\n",
    "Deployment guardrails are a set of model deployment options in Amazon SageMaker Inference to update your machine learning models in production. Using the **fully managed** deployment options, you can control the switch from the current model in production to a new one. \n",
    "\n",
    "## BLUE/GREEN Deployment\n",
    "Traffic shifting modes in blue/green deployments, such as canary and linear, give you granular control over the traffic shifting process from your current model to the new one during the course of the update. There are also built-in safeguards such as auto-rollbacks that help you catch issues early and automatically take corrective action before they significantly impact production.\n",
    "\n",
    "In this lab, we'll leverage SageMaker deployment guardrail feature to perform continue deployment using Canary deployment strategy. Specifically, the following steps will be performed:\n",
    "\n",
    "1. Deploy a baseline model to a SageMaker endpoint\n",
    "2. Define a Canary deployment configuration in JSON format\n",
    "3. Deploy a new version of a model with errors to the same SageMaker endpoint\n",
    "4. Perform inferences on the new version of the model\n",
    "5. Observe the rollback action triggered by Cloudwatch alarm\n",
    "6. Deployment a new version of a model without any errors to the same SageMaker endpoiont.\n",
    "7. Perform inference on the new version of the model\n",
    "8. Observe a successful deployment\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81f092b-07f8-4465-b9d5-764131c386a6",
   "metadata": {},
   "source": [
    "Importing the required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2342786a-5da7-422c-be2e-44094130fb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.s3 import S3Uploader\n",
    "from sagemaker import image_uris\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "import time\n",
    "import json\n",
    "from PIL import Image\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4761fc9a-8abf-4492-9e95-e2770b900e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.session.Session()\n",
    "sm = boto3.client(\"sagemaker\")\n",
    "sm_runtime = boto3.client(\"sagemaker-runtime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcaf1e0-4850-4e6b-900d-48f16e710eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"models/xgb-churn-prediction-model\"\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edba91aa-6cd1-4f4d-bdec-a61c622c8be5",
   "metadata": {},
   "source": [
    "### Model artifacts\n",
    "The example we use here is based on a Churn prediction model trained on a public dataset that predicts Mobile Customer Departure. \n",
    "\n",
    "The dataset we use is publicly available and was mentioned in the book [Discovering Knowledge in Data](https://www.amazon.com/dp/0470908742/) by Daniel T. Larose. It is attributed by the author to the University of California Irvine Repository of Machine Learning Datasets. \n",
    "\n",
    "This particular churn prediction model a binary classification model, trained using Xgboost. The complete step for training the model using the dataset can be found [here](xgboost_customer_churn.ipynb).\n",
    "\n",
    "Since the objective for this lab is on the deployment guardrail, we'll use a pretrained model provided in this lab so that we don't need to go through the training process which could be time consuming.\n",
    "\n",
    "However, feel free to run the [notebook](xgboost_customer_churn.ipynb), or make any modifications to adapt to your use case accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa857236-17c6-49f8-9d05-67beee0d7483",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_url = S3Uploader.upload(local_path=\"model/xgb-churn-prediction-model.tar.gz\",\n",
    "desired_s3_uri=f\"s3://{bucket}/{prefix}\")\n",
    "\n",
    "model_url2 = S3Uploader.upload(local_path=\"model/xgb-churn-prediction-model2.tar.gz\",\n",
    "desired_s3_uri=f\"s3://{bucket}/{prefix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0627a8c8-8339-4102-afb5-502bc80cd4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_uri = image_uris.retrieve('xgboost', boto3.Session().region_name, '0.90-1')\n",
    "\n",
    "# using newer version of XGBoost which is incompatible, in order to simulate model faults\n",
    "image_uri2 = image_uris.retrieve('xgboost', boto3.Session().region_name, '1.2-1')\n",
    "image_uri3 = image_uris.retrieve('xgboost', boto3.Session().region_name, '0.90-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec8d426-923b-4a5d-83d3-908377b178b4",
   "metadata": {},
   "source": [
    "## Deploy a Model in SageMaker\n",
    "### Create a SageMaker Model\n",
    "In the following section, we create our model definitions. We start with deploying the pre-trained churn prediction models. Here, we create the model objects with the image and model data. The three URIs correspond to the baseline version, an incompatible version, and a correct new model version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3468f1-8b24-4a51-9742-3ebd0581ff3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f\"DEMO-xgb-churn-pred-{datetime.now():%Y-%m-%d-%H-%M-%S}\" \n",
    "model_name2 = f\"DEMO-xgb-churn-pred2-{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    "model_name3 = f\"DEMO-xgb-churn-pred3-{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    "\n",
    "resp = sm.create_model(\n",
    "    ModelName=model_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    Containers=[{\n",
    "       'Image': image_uri,\n",
    "       'ModelDataUrl': model_url\n",
    "     }])\n",
    "\n",
    "resp = sm.create_model(\n",
    "    ModelName=model_name2,\n",
    "    ExecutionRoleArn=role,\n",
    "    Containers=[{\n",
    "       'Image':image_uri2,\n",
    "       'ModelDataUrl': model_url2\n",
    "     }])\n",
    "\n",
    "resp = sm.create_model(\n",
    "    ModelName=model_name3,\n",
    "    ExecutionRoleArn=role,\n",
    "    Containers=[{\n",
    "       'Image':image_uri3,\n",
    "       'ModelDataUrl': model_url2\n",
    "     }])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0da297-9023-416b-adfd-ca94868362d2",
   "metadata": {},
   "source": [
    "### Create a SageMaker Model Configuration\n",
    "Next, we'll create the endpoint configurations associated with the model objects created in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57640837-9329-4169-a179-e176cff7c974",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_config_name = f\"DEMO-EpConfig-1-{datetime.now():%Y-%m-%d-%H-%M-%S}\" \n",
    "ep_config_name2 = f\"DEMO-EpConfig-2-{datetime.now():%Y-%m-%d-%H-%M-%S}\" \n",
    "ep_config_name3 = f\"DEMO-EpConfig-3-{datetime.now():%Y-%m-%d-%H-%M-%S}\"\n",
    "\n",
    "resp = sm.create_endpoint_config(\n",
    "     EndpointConfigName=ep_config_name,\n",
    "     ProductionVariants=[\n",
    "        {\n",
    "          'VariantName': \"AllTraffic\",\n",
    "          'ModelName': model_name,\n",
    "          'InstanceType': \"ml.m5.xlarge\",\n",
    "          \"InitialInstanceCount\": 2\n",
    "        }\n",
    "      ])\n",
    "\n",
    "resp = sm.create_endpoint_config(\n",
    "     EndpointConfigName=ep_config_name2,\n",
    "     ProductionVariants=[\n",
    "        {\n",
    "          'VariantName': \"AllTraffic\",\n",
    "          'ModelName': model_name2,\n",
    "          'InstanceType': \"ml.m5.xlarge\",\n",
    "          \"InitialInstanceCount\": 2\n",
    "        }\n",
    "      ])\n",
    "\n",
    "\n",
    "resp = sm.create_endpoint_config(\n",
    "      EndpointConfigName=ep_config_name3,\n",
    "      ProductionVariants=[\n",
    "         {\n",
    "           'VariantName': \"AllTraffic\",\n",
    "           'ModelName': model_name3,\n",
    "           'InstanceType': \"ml.m5.xlarge\",\n",
    "           \"InitialInstanceCount\": 2\n",
    "         }\n",
    "     ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1220cd-1d16-4e5d-860f-b5733f4552ab",
   "metadata": {},
   "source": [
    "## Create a SageMaker Model endpoint\n",
    "In the following, we'll deploy the first model as a SageMaker endpoint. This model will be used as our baseline production model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfde50d-15bb-4fd4-be1b-39202b4a3646",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = model_name\n",
    "resp = sm.create_endpoint(\n",
    "          EndpointName=endpoint_name,\n",
    "          EndpointConfigName=ep_config_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38635fd2-8c61-4eb5-ad30-72e1dd5412fd",
   "metadata": {},
   "source": [
    "Wait for the status to be ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f297dfb2-3e51-4575-8f61-35ff82e754ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_endpoint_in_service(endpoint_name):\n",
    "    endpoint_deployment_status = \"\"\n",
    "    while True:\n",
    "        response = sm.describe_endpoint(EndpointName=endpoint_name)\n",
    "        endpoint_deployment_status = response['EndpointStatus']\n",
    "        if endpoint_deployment_status in [\"OutOfService\", \"InService\", \"Failed\", \"UpdateRollbackFailed\"]:\n",
    "            break\n",
    "        print(f\"Deployment status: {endpoint_deployment_status}\")\n",
    "        time.sleep(20)\n",
    "    print(f\"Final Deployment status: {endpoint_deployment_status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915e4d22-e9e8-4e32-b43a-2f93b159f1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_for_endpoint_in_service(endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df35d31-34f2-476e-80e2-ee5444d2d29f",
   "metadata": {},
   "source": [
    "## Simulate Inference Traffic\n",
    "After a successful model deployment, we will start sending requests to the SageMaker endpoint. \n",
    "We'll be using the sample data provided in this lab. We'll also capture the status of the requests to help us understand the state of the endpoint throughout the deployment process. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e963984b-3057-4daa-a5be-9a017fb6a645",
   "metadata": {},
   "source": [
    "Define a helper function that invoke the model to predict churn on every entry in the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1c9700-55e1-48eb-a83d-3da2734c8427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_endpoint(endpoint_name, max_invocations=300, wait_interval_sec=1, should_raise_exp=False):\n",
    "    print(f\"Sending test traffic to the endpoint {endpoint_name}. \\nPlease wait...\")\n",
    "\n",
    "    count = 0\n",
    "    with open('test_data/test.csv', 'r') as f:\n",
    "        for row in f:\n",
    "            payload = row.rstrip('\\n')\n",
    "            try:\n",
    "                response = sm_runtime.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                                      ContentType='text/csv',\n",
    "                                                      Body=payload)\n",
    "                response['Body'].read()\n",
    "                print(\".\", end=\"\", flush=True)\n",
    "            except Exception as e:\n",
    "                print(\"E\", end=\"\", flush=True)\n",
    "                if should_raise_exp:\n",
    "                    raise e\n",
    "            count += 1\n",
    "            if count > max_invocations:\n",
    "                break\n",
    "            time.sleep(wait_interval_sec)\n",
    "\n",
    "    print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadea136-4d8c-4d41-b6ee-92efbafa88db",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_endpoint(endpoint_name, max_invocations=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35862d45-77c2-4b96-ade6-3a3e7cb39fc7",
   "metadata": {},
   "source": [
    "## Monitor SageMaker endpoint using Cloudwatch Metrics\n",
    "By default, SageMaker hosting service provides various metrics that allow you to monitor the health of the endpoints. All metrics are hosted in CloudWatch Metrics. The default metrics from SageMaker are described in the following:\n",
    "\n",
    "### SageMaker Endpoint Invocation Metrics\n",
    "\n",
    "* **Cloudwatch Metric namespace:** AWS/SageMaker\n",
    "* **Metrics Frequency:** 1-minute.\n",
    "* **Network latency:** The time that it takes between making a request to the SageMaker Runtime Runtime API and receiving a response back from the SageMaker Runtime Runtime API.\n",
    "* **Overhead latency:** The time that it takes to transport a request to the model container from the SageMaker Runtime Runtime API and transport the response back to the SageMaker Runtime Runtime API.\n",
    "* **Model latency** The time that it takes the model container to process the request and return a response.\n",
    "* **Invocation4XXErrors** The number of InvokeEndpoint requests where the model returned a 4xx HTTP response code.\n",
    "* **Invocation5XXErrors:** The number of InvokeEndpoint requests where the model returned a 5xx HTTP response code. \n",
    "* **InvocationModelErrors** - The number of model invocation requests which did not result in 2XX HTTP response.\n",
    "\n",
    "The following diagram depicts the network traffic pattern and the associated latency from the origin to SageMaker endpoint. \n",
    "\n",
    "![CW SageMaker metrics](images/sm-cw-metrics.jpg)\n",
    "\n",
    "Please refer to this [blog](https://aws.amazon.com/blogs/machine-learning/best-practices-for-load-testing-amazon-sagemaker-real-time-inference-endpoints/) to learn more about the total endpoint latency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a34dd6b-691a-43bd-bdda-6af95331a340",
   "metadata": {},
   "source": [
    "Let's visualize these metrics in the following section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb81b4e-dc9a-4c15-9c89-7e5cb2c946b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cw_client = boto3.client(\"cloudwatch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b379c9a-92a0-40af-92b5-cc1171c94acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_cw_metrics(metric_dims, endpoint_name, endpoint_config_names):\n",
    "    images = []\n",
    "    for metric_dim in metric_dims:\n",
    "        stat = \"Sum\"\n",
    "        if \"Latency\" in metric_dim:\n",
    "            stat = \"Average\"\n",
    "\n",
    "        metrics = []\n",
    "        for endpoint_config_name in endpoint_config_names:\n",
    "            metrics.append([ \"AWS/SageMaker\", metric_dim, \"EndpointName\", endpoint_name, \"VariantName\", \"AllTraffic\", \"EndpointConfigName\", endpoint_config_name])\n",
    "            \n",
    "        metric_widget = {\n",
    "            \"metrics\": metrics,\n",
    "            \"view\": \"timeSeries\",\n",
    "            \"stacked\": False,\n",
    "            \"stat\": stat,\n",
    "            \"period\": 60,\n",
    "            \"width\": 1000,\n",
    "            \"height\": 200,\n",
    "            \"start\": \"-PT1H\",\n",
    "            \"end\": \"P0D\"\n",
    "        }\n",
    "        response = cw_client.get_metric_widget_image(\n",
    "            MetricWidget=json.dumps(metric_widget)\n",
    "        )\n",
    "        images.append(Image.open(io.BytesIO(response[\"MetricWidgetImage\"])))\n",
    "    for image in images:\n",
    "        image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cb1a5f-45a4-44e0-8fce-5dc432799990",
   "metadata": {},
   "source": [
    "In the following section, we visualize the relevant cloudwatch metrics. We will focus on the metrics around invocation counts, server/client errors and model latency. \n",
    "\n",
    "Here are the metrics:\n",
    "\n",
    "* Invocations\n",
    "* Invocation4XXErrors\n",
    "* Invocation5XXErrors\n",
    "* ModelLatency\n",
    "* OverheadLatency\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8b6c48-4992-41dd-8285-607d81a6861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_dims = [\"Invocations\", \"Invocation4XXErrors\", \"Invocation5XXErrors\", \"ModelLatency\", \"OverheadLatency\"]\n",
    "ep_config_names = [ep_config_name]\n",
    "display_cw_metrics(metric_dims, endpoint_name, ep_config_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476d3b67-ba04-4817-9865-288bf01821d3",
   "metadata": {},
   "source": [
    "## Monitor SageMaker Endpoint Performance\n",
    "In the following section, we are going to monitor the endpoint performance by setting up some custom Cloudwatch Alarms. We will use these alarm with actions if the endpoint is not functioning as expected.\n",
    "\n",
    "In our example, the action for the alarm would be to rollback the endpoint automatically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6a5daf-bc45-4ea4-b9f8-c5e099b93b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_auto_rollback_alarm(alarm_name, endpoint_name, variant_name, metric_name, statistic, threshold):\n",
    "    cw_client.put_metric_alarm(\n",
    "        AlarmName=alarm_name,\n",
    "        AlarmDescription='Test SageMaker endpoint deployment auto-rollback alarm',\n",
    "        ActionsEnabled=False,\n",
    "        Namespace='AWS/SageMaker',\n",
    "        MetricName=metric_name,\n",
    "        Statistic=statistic,\n",
    "        Dimensions=[\n",
    "            {\n",
    "            'Name': 'EndpointName',\n",
    "            'Value': endpoint_name\n",
    "            },\n",
    "            {\n",
    "            'Name': 'VariantName',\n",
    "            'Value': variant_name\n",
    "            }\n",
    "        ],\n",
    "        Period=60,\n",
    "        EvaluationPeriods=1,\n",
    "        Threshold=threshold,\n",
    "        ComparisonOperator='GreaterThanOrEqualToThreshold',\n",
    "        TreatMissingData='notBreaching'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d921436c-3f28-46fa-b9de-7e8212da348f",
   "metadata": {},
   "source": [
    "Let's set an automatic rollback alarms as followed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3340d6-681f-46c1-a930-998186ea6b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alarm on 1% 5xx error rate for 1 minute\n",
    "create_auto_rollback_alarm(\"error_alarm\", endpoint_name, 'AllTraffic', 'Invocation4XXErrors', 'Sum', 1)\n",
    "# alarm on model latency >= 10 ms for 1 minute\n",
    "create_auto_rollback_alarm(\"latency_alarm\", endpoint_name, 'AllTraffic', 'ModelLatency', 'Average', 10000)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "550698d5-c275-4f44-8444-dcdb826a4653",
   "metadata": {},
   "source": [
    "### Setup Blue/Green Deployment\n",
    "So far, we have deployed a single endpoint with test traffics. We have also created some alarms for the endpoint so that if the defined threshold is exceed, it'll trigger a rollback automatically.  \n",
    "\n",
    "SageMaker deployment guardrail supports 3 types of BLUE/GREEN deployment strategies: \n",
    "\n",
    "* All at once\n",
    "* Canary\n",
    "* Linear \n",
    "\n",
    "The following detail describes in greater detail for each deployment strategy and discuss the advantage/disadvantages for each strategy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c57a33f-c14e-43ee-be25-789e3968a8f1",
   "metadata": {},
   "source": [
    "| Name | What is it | Pros | Cons | Recommendation |\n",
    "|:--------:|:--------:|:--------:|:--------:|:--------:|\n",
    "| All at once | Shifts all of the traffic to the new fleet in a single step. | Minimizes the overall update duration. | Regressive updates affect 100% of the traffic. | Use this option to minimize update time and cost. |\n",
    "| Canary | Traffic shifts in two steps. The first (canary) step shifts a small portion of the traffic followed by the second step, which shifts the remainder of the traffic. | Confines the blast radius of regressive updates to only the canary fleet. | Both fleets are operational in parallel for entire deployment. | Use this option to balance between minimizing the blast radius of regressive updates and minimizing the time that two fleets are operational. |\n",
    "| Linear | A fixed portion of the traffic shifts in a pre-specified number of equally spaced steps. | Minimizes the risk of regressive updates by shifting traffic over several steps. | The update duration and cost are proportional to the number of steps. | Use this option to minimize risk by spreading out deployment across multiple steps. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba22cd2-71da-4b1b-8f66-027fa23a57a2",
   "metadata": {},
   "source": [
    "### Canary Deployment Strategy\n",
    "In the next section, we'll adopt the canary deployment strategy and observe the effects in action. To simulate a BLUE/GREEN deployment, we'll deploy another endpoint following deployment configuration with traffic shifting from the old to the new stack. \n",
    "\n",
    "The following diagram depicts the expected bahavior when errors are encountered during the BLUE/GREEN Canary deployment process:\n",
    "\n",
    "![sm-deployment-guardrail-canary](images/sm-deployment-guardrail-rollback-canary.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def97cde-7d41-4d09-a283-61e94dab67b0",
   "metadata": {},
   "source": [
    "## Deployment Configuration\n",
    "\n",
    "First, we need to define a deployment config. The parameters are described in the following:\n",
    "\n",
    "* **EndpointName**: The name of the existing endpoint you want to update.\n",
    "* **EndpointConfigName**: The name of the endpoint configuration you want to use.\n",
    "* **BlueGreenUpdatePolicy**: Define the type of deployment option. For example, CANARY, ALL_AT_ONCE or LINEAR.\n",
    "* **CanarySize**: Batch size for the first step to turn on traffic on the new endpoint fleet. Value must be less than or equal to 50% of the variant's total instance count. This could be a percentage of the capacity, or instance count.\n",
    "* **WaitIntervalInSeconds**: The waiting time (in seconds) between incremental steps to turn on traffic on the new endpoint fleet.\n",
    "* **TerminationWaitInSeconds**: Additional waiting time in seconds after the completion of an endpoint deployment before terminating the old endpoint fleet.\n",
    "* **MaximumExecutionTimeoutInSeconds**: Maximum execution timeout for the deployment. The timeout value should be larger than the total waiting time specified in TerminationWaitInSeconds and WaitIntervalInSeconds.\n",
    "* **AutoRollbackConfiguration**: Automatic rollback configuration for handling endpoint deployment failures and recovery. This is where you can add your CloudWatch alarms by name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf1ce9f-006d-4bb5-8951-b2f44f6ac9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "canary_deployment_config = {\n",
    "    \"BlueGreenUpdatePolicy\": {\n",
    "        \"TrafficRoutingConfiguration\": {\n",
    "            \"Type\": \"CANARY\",\n",
    "            \"CanarySize\": {\n",
    "                \"Type\": \"INSTANCE_COUNT\", # or use \"CAPACITY_PERCENT\" as 30%, 50%\n",
    "                \"Value\": 1\n",
    "            },\n",
    "            \"WaitIntervalInSeconds\": 180, # wait for 5 minutes before enabling traffic on the rest of fleet\n",
    "        },\n",
    "        \"TerminationWaitInSeconds\": 120, # wait for 2 minutes before terminating the old stack\n",
    "        \"MaximumExecutionTimeoutInSeconds\": 1800 # maximum timeout for deployment\n",
    "    },\n",
    "    \"AutoRollbackConfiguration\": {\n",
    "        \"Alarms\": [\n",
    "            {\n",
    "                \"AlarmName\": \"error_alarm\"\n",
    "            },\n",
    "            {\n",
    "                \"AlarmName\": \"latency_alarm\"\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9f5c8e-fae4-42fd-9c63-4417ff5bcd09",
   "metadata": {},
   "source": [
    "Update endpoint request with new DeploymentConfig parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7563ff5e-c66d-4035-bafb-a83d4b996b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.update_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=ep_config_name2,\n",
    "    DeploymentConfig=canary_deployment_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b98e1f3-6e0c-46c3-a028-292fa1998f5e",
   "metadata": {},
   "source": [
    "## Simulate SageMaker Inference fraffic of a FAILED Canary Deployment\n",
    "Similar to the deployed base model, we will start sending requests to the SageMaker endpoint with a new endpoint configuration and deployment strategy configuration applied to it. We'll also capture the status of the requests to help us understand the state of the endpoint throughout the deployment process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ad714d-e484-49d1-8510-0a0938cd946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_endpoint(endpoint_name, max_invocations=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03978e5-b6c3-42da-940d-b5825c9a7b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_config_names.append(ep_config_name2)\n",
    "display_cw_metrics(metric_dims, endpoint_name, list(set(ep_config_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420dd18a-2f9b-41e9-a662-d04a71125d2a",
   "metadata": {},
   "source": [
    "## Cloudwatch Alarm Status change\n",
    "In the following section, we'll examine the status cloudwatch alarm changed when the threshold was exceed. \n",
    "The alarm triggered an action for SageMaker deployment guardrail to initiate the rollback action.\n",
    "\n",
    "The alarm would finally return to the OK state after the rollback is complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0968d838-9c7d-4403-9077-4d96682bf9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_cw_metric_alarm(alarm_name, endpoint_name):\n",
    "    metric_widget = {\n",
    "        \"metrics\": [\n",
    "            [ \"AWS/SageMaker\", \"Invocation4XXErrors\", \"EndpointName\", endpoint_name, \n",
    "             \"VariantName\", \"AllTraffic\", { \"stat\": \"Sum\" } ]\n",
    "        ],\n",
    "        \"view\": \"timeSeries\",\n",
    "        \"stacked\": False,\n",
    "        \"period\": 60,\n",
    "        \"title\": alarm_name,\n",
    "        \"annotations\": {\n",
    "            \"horizontal\": [\n",
    "                {\n",
    "                    \"label\": \"Invocation4XXErrors >= 1 for 1 datapoints within 1 minute\",\n",
    "                    \"value\": 1\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"width\": 1201,\n",
    "        \"height\": 200,\n",
    "        \"start\": \"-PT3H\",\n",
    "        \"end\": \"P0D\"\n",
    "    }\n",
    "    response = cw_client.get_metric_widget_image(\n",
    "        MetricWidget=json.dumps(metric_widget)\n",
    "    )\n",
    "    image = Image.open(io.BytesIO(response[\"MetricWidgetImage\"]))\n",
    "    image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13620847-0139-4634-8287-c6cdb36effa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = cw_client.describe_alarm_history(\n",
    "    AlarmName='error_alarm',\n",
    "    AlarmTypes=['MetricAlarm'],\n",
    "    HistoryItemType='StateUpdate',\n",
    "    StartDate=datetime(2015, 1, 1),\n",
    "    EndDate=datetime(2024, 12, 31),\n",
    "    ScanBy='TimestampDescending'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3208344-e8e7-4ad4-9bd6-9ecd73612131",
   "metadata": {},
   "outputs": [],
   "source": [
    "for alarm_state in [(x['Timestamp'].strftime(\"%m/%d/%Y, %H:%M:%S\"), x['HistorySummary']) for x in response['AlarmHistoryItems']]:\n",
    "    print(alarm_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6983da7-ad00-4ceb-af0c-414b99bbcf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_cw_metric_alarm(\"error_alarm\", endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983a0e55-be10-43af-884e-154e26bab6c9",
   "metadata": {},
   "source": [
    "### Successful Canary Deployment\n",
    "In the following section, we'll perform the deployment process again, the difference is this time we update the endpoint configuration to a valid version. We'll reuse the same canary deployment config as the rollback case.\n",
    "\n",
    "The following diagram depicts a successful Canary deployment scenario:\n",
    "![successful canary deployment](images/sm-deployment-guardrail-canary-success.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b33051-0f4e-41cf-a9bc-4d573ac557b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update endpoint with a valid version of DeploymentConfig\n",
    "sm.update_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=ep_config_name3,\n",
    "    RetainDeploymentConfig=True # Reuse the same deployment configuration\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb07d98d-b2a1-4099-bdf8-12c7fdb7a5e5",
   "metadata": {},
   "source": [
    "## Simulate SageMaker Inference traffic of a succesful deployment\n",
    "Similar to the failed deployment in the previous section, we will start sending requests to the SageMaker endpoint with a new endpoint configuration. This time, we expect the deployment to be successful. We'll also capture the status of the requests to help us understand the state of the endpoint throughout the deployment process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b7fdf5-fad3-44ad-82de-8e1d0f15a0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoke_endpoint(endpoint_name, max_invocations=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75968dc6-499d-48df-be71-9208195c781b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep_config_names.append(ep_config_name3)\n",
    "display_cw_metrics(metric_dims, endpoint_name, list(set(ep_config_names)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97fe8e9-f3d7-44d2-946b-2752edbf8e5c",
   "metadata": {},
   "source": [
    "Similar to the rollback example, let's examine the alarm state for this deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cf586e-5ccb-4495-b3ea-7a6f122e1f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_cw_metric_alarm(\"error_alarm\", endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac77688d-e2f7-4106-bc37-b5ed27e2d195",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "In this lab, we learn how to leverage SageMaker Deployment Guardrail to manage the BLUE/GREEN deployment process.\n",
    "We started by deploying a valid endpoint, then ran tests against the endpoint to validate the deployment working as expected. \n",
    "\n",
    "After a successful test, we created a set of cloudwatch alarms, along with a deployment configuration to setup a canary deployment strategy. \n",
    "\n",
    "To validate the canary deployment, we deployed a model that contains errors to simulate a rollback scenario. We validated through Cloudwatch metrics that SageMaker deployment guardrail was able rollback the deployment to a previous version after the cloudwatch alarm was triggered. \n",
    "\n",
    "Lastly, we deployed a new version of the model without any errors to similate a successful deployment. We validated through Cloudwatch metrics that SageMaker deployment guardrail was able to sucessfully shift all traffic to the new model, completing the new deployment process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe986e8-166f-4b6b-b1a7-823081283bf8",
   "metadata": {},
   "source": [
    "# Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2585d153-4524-4d00-80eb-a2cc5c290c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.delete_endpoint(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcda2dd-1a68-4cf4-8a17-c391bb1b3fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
